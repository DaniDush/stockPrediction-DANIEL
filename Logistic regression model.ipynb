{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression model - Daniel shalam\n",
    "# I didnt used this model for the prediction i just wanted to write it for myself\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def train(features, labels, weights, leraning_rate, iters):\n",
    "    cost_history = []\n",
    "\n",
    "    for i in range(iters):\n",
    "        weights = gradiant_decent(features, labels, weights, leraning_rate)\n",
    "\n",
    "        # Calculate error for auditing purposes\n",
    "        cost = cost_function(features, labels, weights)\n",
    "        cost_history.append(cost)\n",
    "\n",
    "        # Log Progress\n",
    "        if i % 1000 == 0:\n",
    "            print\n",
    "            \"iter: \" + str(i) + \" cost: \" + str(cost)\n",
    "\n",
    "    return weights, cost_history\n",
    "\n",
    "\n",
    "# Logistic regression model\n",
    "def logistic_regression(X, Y):\n",
    "\n",
    "    # Initializing variables\n",
    "    w0 = 0\n",
    "    w1 = 0\n",
    "    w2 = 0\n",
    "    w3 = 0\n",
    "    L = 0.001\n",
    "    epochs = 300\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        y_pred = predict(X, w0, w1, w2, w3)\n",
    "        W0 = -2 * sum((Y - y_pred) * y_pred * (1 - y_pred))  # Derivative of loss of w0\n",
    "        W1 = -2 * sum(X * (Y - y_pred) * y_pred * (1 - y_pred))  # Derivative of loss of w1\n",
    "        \n",
    "        # Update w0 and w1\n",
    "        w0 = w0 - L * W0\n",
    "        w1 = w1 - L * W1\n",
    "        \n",
    "\n",
    "    return W0, W1, W2, W3\n",
    "\n",
    "\n",
    "# Gradiant decent\n",
    "def gradiant_decent(features, labels, weights, leraning_rate):\n",
    "    num_labels = len(features)\n",
    "\n",
    "    # 1 - Get Predictions\n",
    "    predictions = predict(features, weights)\n",
    "\n",
    "    # 2 Transpose features from (200, 3) to (3, 200)\n",
    "    # So we can multiply w the (200,1)  cost matrix.\n",
    "    # Returns a (3,1) matrix holding 3 partial derivatives --\n",
    "    # one for each feature -- representing the aggregate\n",
    "    # slope of the cost function across all observations\n",
    "    gradient = np.dot(features.T, predictions - labels)\n",
    "\n",
    "    # 3 Take the average cost derivative for each feature\n",
    "    gradient /= num_labels\n",
    "\n",
    "    # 4 - Multiply the gradient by our learning rate\n",
    "    gradient *= leraning_rate\n",
    "\n",
    "    # 5 - Subtract from our weights to minimize cost\n",
    "    weights -= gradient\n",
    "\n",
    "    return weights\n",
    "\n",
    "\n",
    "# Using cross entropy cost function - Cost = (labels*log(predictions) + (1-labels)*log(1-predictions) ) / len(labels)\n",
    "def cost_function(features, labels, weights):\n",
    "    num_labels = len(labels)\n",
    "\n",
    "    predictions = predict(features, weights)\n",
    "\n",
    "    # Take the error when label=1\n",
    "    class1_cost = -labels * np.log(predictions)\n",
    "\n",
    "    # Take the error when label=0\n",
    "    class2_cost = (1 - labels) * np.log(1 - predictions)\n",
    "\n",
    "    # Take the sum of both costs\n",
    "    cost = class1_cost - class2_cost\n",
    "\n",
    "    # Take the average cost\n",
    "    cost = (1 / num_labels) * cost.sum()\n",
    "\n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a threshold (decision boundry)\n",
    "def decision_boundary(prob):\n",
    "    return 1 if prob >= (1 / 2) else 0\n",
    "\n",
    "\n",
    "# Activation function\n",
    "def sigmoid(z):\n",
    "    return (1 / (1 + np.exp(-z)))\n",
    "\n",
    "\n",
    "# Predicting the probability that the feature is 1\n",
    "def predict(features, *weights):\n",
    "    z = np.dot(features, weights)\n",
    "\n",
    "    return sigmoid(z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
